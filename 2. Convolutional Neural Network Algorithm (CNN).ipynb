{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Convolutional Neural Network Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n  32=No.of Feature Map Layers after applying feature detector (or) No.of filter or future detectors applying to input layer.\\n  3,3= Shape of the feature map layer row*column (or) shape of the feature detector in row*column\\n  input_shape= We are rescaling all input values to 64 *64 in 3 layers(red,green,Blue)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step-1 Create Convolutional Layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "\n",
    "cnn=Sequential()\n",
    "cnn.add(Convolution2D(32,3,3,input_shape=(64,64,3),activation='relu'))\n",
    "'''\n",
    "  32=No.of Feature Map Layers after applying feature detector (or) No.of filter or future detectors applying to input layer.\n",
    "  3,3= Shape of the feature map layer row*column (or) shape of the feature detector in row*column\n",
    "  input_shape= We are rescaling all input values to 64 *64 in 3 layers(red,green,Blue)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Step -2 Create Polling Layers\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "'''pool_size= Pooling size after convolution layer. We are applying max value for each 2*2 values in convolution layer'''\n",
    "\n",
    "# Create Second convolution layer to get better accuracy for test set\n",
    "cnn.add(Convolution2D(32,3,3,activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No Need to customize any parameters it will convert pooled layers to flatten layers'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step-3 Create flatten to pooled layer\n",
    "from keras.layers import Flatten\n",
    "cnn.add(Flatten())\n",
    "'''No Need to customize any parameters it will convert pooled layers to flatten layers'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Step-4 Fully Connection Layer\n",
    "from keras.layers import Dense\n",
    "# First Fully connected hidden layer\n",
    "cnn.add(Dense(output_dim=128,activation='relu'))\n",
    "# Second Fully Connected hidden layer\n",
    "cnn.add(Dense(output_dim=128,activation='relu'))\n",
    "# Output layer\n",
    "cnn.add(Dense(output_dim=1,activation='sigmoid'))\n",
    "# Compile the CNN\n",
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=250, epochs=25, validation_steps=2000)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arunkumar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "250/250 [==============================] - 197s 787ms/step - loss: 0.6714 - acc: 0.5729 - val_loss: 0.6269 - val_acc: 0.6584\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 145s 582ms/step - loss: 0.6032 - acc: 0.6747 - val_loss: 0.5606 - val_acc: 0.7163\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 148s 592ms/step - loss: 0.5491 - acc: 0.7201 - val_loss: 0.5275 - val_acc: 0.7336\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 145s 580ms/step - loss: 0.5216 - acc: 0.7371 - val_loss: 0.5289 - val_acc: 0.7346\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 145s 581ms/step - loss: 0.4983 - acc: 0.7531 - val_loss: 0.4894 - val_acc: 0.7629\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 150s 599ms/step - loss: 0.4733 - acc: 0.7723 - val_loss: 0.4995 - val_acc: 0.7612\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 147s 587ms/step - loss: 0.4548 - acc: 0.7893 - val_loss: 0.4691 - val_acc: 0.7804\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 145s 581ms/step - loss: 0.4402 - acc: 0.7900 - val_loss: 0.4851 - val_acc: 0.7746\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 146s 583ms/step - loss: 0.4240 - acc: 0.8040 - val_loss: 0.4640 - val_acc: 0.7896\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 150s 599ms/step - loss: 0.4211 - acc: 0.8044 - val_loss: 0.4531 - val_acc: 0.7910\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 150s 600ms/step - loss: 0.4039 - acc: 0.8147 - val_loss: 0.5158 - val_acc: 0.7549\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 146s 583ms/step - loss: 0.3876 - acc: 0.8194 - val_loss: 0.4813 - val_acc: 0.7579\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 150s 601ms/step - loss: 0.3789 - acc: 0.8246 - val_loss: 0.4725 - val_acc: 0.7920\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 146s 585ms/step - loss: 0.3556 - acc: 0.8397 - val_loss: 0.4716 - val_acc: 0.7880\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 147s 586ms/step - loss: 0.3509 - acc: 0.8446 - val_loss: 0.4803 - val_acc: 0.7923\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 151s 602ms/step - loss: 0.3299 - acc: 0.8614 - val_loss: 0.4685 - val_acc: 0.7905\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 151s 602ms/step - loss: 0.3251 - acc: 0.8553 - val_loss: 0.4604 - val_acc: 0.8018\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 146s 582ms/step - loss: 0.3114 - acc: 0.8610 - val_loss: 0.4706 - val_acc: 0.7971\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 146s 585ms/step - loss: 0.3015 - acc: 0.8686 - val_loss: 0.5103 - val_acc: 0.7975\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 146s 582ms/step - loss: 0.2895 - acc: 0.8748 - val_loss: 0.4832 - val_acc: 0.8050\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 160s 639ms/step - loss: 0.2835 - acc: 0.8809 - val_loss: 0.4942 - val_acc: 0.7870\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 250s 999ms/step - loss: 0.2653 - acc: 0.8916 - val_loss: 0.4754 - val_acc: 0.8006\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 274s 1s/step - loss: 0.2468 - acc: 0.8971 - val_loss: 0.5885 - val_acc: 0.7764\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 302s 1s/step - loss: 0.2345 - acc: 0.8996 - val_loss: 0.5273 - val_acc: 0.7922\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 260s 1s/step - loss: 0.2313 - acc: 0.9004 - val_loss: 0.5383 - val_acc: 0.7943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24374467a48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the CNN to the images\n",
    "# We used Image aqumentation code from keras documention\n",
    "# Image Aqumentation to provent overfitting the training data and which cause less accuracy for test set.\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "'''ImageAqumentation is used to split the dataset into folds and each fold it will keep reuse the existing data using flip \n",
    "   and compress image so that it can learn all feature better'''\n",
    "\n",
    "# It will re scale the training data from different scale to same scale\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True)\n",
    "# Re-scale test set data from different scale to same scale\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Locating the training set folder \n",
    "\n",
    "training_set=train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                               # Target size should match with input_dim of convolution layer\n",
    "                                              target_size=(64,64),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='binary')\n",
    "# Locating the test set fold\n",
    "\n",
    "test_set=test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                         target_size=(64,64),\n",
    "                                         batch_size=32,\n",
    "                                         class_mode='binary')\n",
    "\n",
    "# Generating the predictions\n",
    "\n",
    "cnn.fit_generator(training_set,\n",
    "                  # training set data size\n",
    "                 samples_per_epoch=8000,\n",
    "                 nb_epoch=25,\n",
    "                 validation_data=test_set,\n",
    "                 nb_val_samples=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got 90.04% accuracy for training set and 79.43% accuracy for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- convert image to array-------\n",
      "[[[ 54.  58.   7.]\n",
      "  [ 58.  63.   9.]\n",
      "  [ 64.  67.  10.]\n",
      "  ...\n",
      "  [136. 144.  71.]\n",
      "  [140. 150.  77.]\n",
      "  [139. 149.  78.]]\n",
      "\n",
      " [[ 48.  54.   6.]\n",
      "  [ 51.  58.   7.]\n",
      "  [ 58.  63.   9.]\n",
      "  ...\n",
      "  [129. 137.  64.]\n",
      "  [139. 149.  78.]\n",
      "  [141. 151.  80.]]\n",
      "\n",
      " [[ 48.  56.   7.]\n",
      "  [ 48.  56.   7.]\n",
      "  [ 54.  61.  10.]\n",
      "  ...\n",
      "  [123. 130.  63.]\n",
      "  [136. 145.  80.]\n",
      "  [140. 149.  82.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 46.  55.  12.]\n",
      "  [ 42.  50.   9.]\n",
      "  [ 38.  49.   9.]\n",
      "  ...\n",
      "  [239. 205. 170.]\n",
      "  [235. 209. 186.]\n",
      "  [229. 202. 173.]]\n",
      "\n",
      " [[ 50.  57.  15.]\n",
      "  [ 42.  50.   9.]\n",
      "  [ 44.  52.  11.]\n",
      "  ...\n",
      "  [234. 200. 162.]\n",
      "  [236. 206. 178.]\n",
      "  [234. 203. 174.]]\n",
      "\n",
      " [[ 53.  59.  13.]\n",
      "  [ 43.  51.  10.]\n",
      "  [ 49.  56.  12.]\n",
      "  ...\n",
      "  [231. 195. 159.]\n",
      "  [235. 213. 190.]\n",
      "  [233. 206. 179.]]]\n",
      "[[1.]]\n",
      "{'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "# Make single prediction observation\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image=image.load_img('dataset/single_prediction/cat_or_dog_1.jpg',target_size=(64,64))\n",
    "# convert the image to array \n",
    "test_image=image.img_to_array(test_image)\n",
    "print(\"---- convert image to array-------\")\n",
    "print(test_image)\n",
    "# error  when checking expected to have 4 dimensions, but got array  with shape(64,64,3)\n",
    "# Adding one more axis to handle error\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "result=cnn.predict(test_image)\n",
    "print(result)\n",
    "print(training_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got correct image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
